\documentclass[12pt,twoside]{article}
\usepackage{jmlda}
\title
%    [Нелинейное ранжирование результатов разведочного информационного поиска] % Краткое название; не нужно, если полное название влезает в~колонтитул
{Нелинейное ранжирование результатов разведочного информационного поиска.}
\author
%    [Мамонов~К.\,Р.] % список авторов для колонтитула; не нужен, если основной список влезает в колонтитул
{Мамонов~К.\,Р.,  Воронцов~К.\,В., Еремеев~М.\,А.} % основной список авторов, выводимый в оглавление
[Мамонов~К.\,Р.$^1$, Воронцов~К.\,В.$^1$, Еремеев~М.\,А.$^1$] % список авторов, выводимый в заголовок; не нужен, если он не отличается от основного
\thanks
%    {Работа выполнена при финансовой поддержке РФФИ, проект \No\,00-00-00000.
%   Научный руководитель:  Стрижов~В.\,В.
{Задачу поставил:  Воронцов~К.\,В.
	 Консультант:  Еремеев~М.\,А.}
\email
{mamonov.kr@phystech.ru, vokov@forecsys.ru, maks5507@yandex.ru}
\organization
{$^1$ Московский физико-технический институт, Москва, Россия}%; $^2$Организация}
\abstract
{Имея коллекцию документов, пользователю порой очень сложно в них разобраться. Существует множество подходов для поиска среди этих документов, но их недостаточно, когда пользователь хочет получить доступ к соответствующим документам в некотором логическом порядке, например, для учебных целей. В данной работе описан алгоритм ранжирования документов от простого к сложному, от общего к частному, то есть в том порядке, в котором пользователю будет легче разбираться в новой для него тематической области. Данный подход даёт пользователю абсолютно новый способ потребления контента.
	
	\bigskip
	\textbf{Ключевые слова}: \emph {граф чтения, тематическое моделирование, информационный поиск}.}
\titleEng
{JMLDA paper example: file jmlda-example.tex}
\authorEng
{Author~F.\,S.$^1$, CoAuthor~F.\,S.$^2$, Name~F.\,S.$^2$}
\organizationEng
{$^1$Organization; $^2$Organization}
\abstractEng
{This document is an example of paper prepared with \LaTeXe\
	typesetting system and style file \texttt{jmlda.sty}.
	
	\bigskip
	\textbf{Keywords}: \emph{keyword, keyword, more keywords}.}
\begin{document}
	
	\maketitle
	
	\section{Введение}
	В связи с последними научными достижениями, особенно развитием интернета, многократно возрос объем текстовой информации, которую приходится обрабатывать человеку. Все более актуальной становится проблема ранжирования информации для более понятной и быстрой её обратоки и понимания.
	
	Предлагается алгоритм построения графа чтения по статьям Википедии \cite{WikiPedia} с применением методов тематичесского моделирования.
	
	Тематические модели широко используются на практике для решения задач ранжирования документов. Одним из продвинутых инструментов в тематическом моделировании является библиотека BigARTM~\cite{vorontsov2015bigartm}. Она предоставляет широкий выбор для настройки модели, используя обширный класс регуляризаторов. 
	
	\section{Постановка задачи}
	Текущий подход к построению подобных графов описан в работе \cite{conf/icde/KoutrikaLS15}. Сначала проводится предобработка текстов --- удаляются стоп-слова и другой шум, все слова приводятся к начальной форме и строится матрица документ-слово. Затем данная матрица переводится LDA алгоритмом\cite{blei2003latent} в матрицу документ-тема и происходит колибровка тематической модели. после этого из полученной матрицы строится частичный порядок документов коллекции и дерево чтения в целом.
	
	Узким местом являются тематические модели. Мы предлагаем применить для них алгоритм BigARTM\cite{vorontsov2015bigartm}, вместо LDA\cite{blei2003latent}, построить мультимодальную тематическую модель \cite{Ianina2016} и использовать в качестве меры общности не энтропию, а долю терминов с узким распределением $p(w|t)$ .
	
	Был взят набор текстовых коллекций Википедии $\mathfrak{D} = \left\{D_i\right\}_{i=1}^{N}$, где каждая коллекция $D$ состоит из документов $d$, словари коллекциий текстов $W$, состоящих из термов $w$, и множества тем $T$, состоящих из тем  $t$.
	
	Распределение вида $p(t|x)$ будем называть тематикой объекта x. Можно говорить о тематике документа $p(t|d)$, терма $p(t|w)$, терма в документе $p(t|d, w)$.
	
	Целью нелинейного ранжирования  является построение частичного порядка на коллекции документов $D$, в частности, это может быть совокупность деревьев (лес документов). Для этого строится тематичесская модель и для каждого документа находится вероятность того, что документ $i$ принадлежит теме $j$, так получается матрица $\theta_{ij}= p(t|d)$. По ней можно для каждого документа посчитать меру общности документа $g(d_i) = \sum\limits_{m} -F_{im}log(F_{im}) $ и меру пересеченния двух документов $o(d_i, d_j) = \frac{F_i\cdot F_j}{|F_i^2|+|F_j^2| - F_i\cdot F_j},$ которые отражают сложность документов и позволяют построить матрицу смежности $A$ требуемого графа.
	
	Критерием качества $S$ нашего алгоритма будем считать величину обратную к среднеквадратичному отклонению между двумя матрицами смежности графов чтения. Эталонные графы с матрицей смежности $\hat{A}$ построим из категорий Википедии. Цель данной работы состоит в решении следующей задачи:
	
	\begin{equation}
	\sum\limits_{i,j = 1}^n(A_{ij}-\hat{A_{ij}})^2\rightarrow \min_{\mathfrak{D}}
	\end{equation}
	
	%\begin{State}
	%    Мотивации и~интерпретации наиболее важны для понимания сути работы.
	%\end{State}
	
	%\begin{Theorem}
	%    Не~менее $90\%$ коллег, заинтересовавшихся Вашей статьёй,
	%    прочитают в~ней не~более~$10\%$ текста.
	%\end{Theorem}
	%
	%\begin{Proof}
	%    Причём это будут именно те~разделы, которые не содержат формул.
	%\end{Proof}
	%
	%\begin{Remark}
	%    Выше показано применение окружений
	%    Def, Theorem, State, Remark, Proof.
	%\end{Remark}
	
	
	%\section{Заключение}
	
	%Желательно, чтобы этот раздел был, причём он не~должен дословно повторять аннотацию.
	%Обычно здесь отмечают,
	%каких результатов удалось добиться,
	%какие проблемы остались открытыми.
	
	
	\bibliographystyle{plain}
	\bibliography{Mamonov2020Project73}
	
	% Решение Программного Комитета:
	%\ACCEPTNOTE
	%\AMENDNOTE
	%\REJECTNOTE
\end{document}
